#!/usr/bin/python3
import argparse
import itertools

import torchvision.transforms as transforms
from torch.utils.data import DataLoader
from torch.autograd import Variable
from PIL import Image
import torch

from models import Generator
from models import Discriminator
from utils import ReplayBuffer
from utils import LambdaLR
from utils import Logger
from utils import weights_init_normal
from datasets import ImageDataset

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--epoch', type=int, default=0, help='starting epoch')
    parser.add_argument('--n_epochs', type=int, default=200, help='number of epochs of training')
    parser.add_argument('--batchSize', type=int, default=10, help='size of the batches')
    parser.add_argument('--dataroot', type=str, default='datasets/horse2zebra/', help='root directory of the dataset')
    parser.add_argument('--lr', type=float, default=0.0002, help='initial learning rate')
    parser.add_argument('--decay_epoch', type=int, default=100,
                        help='epoch to start linearly decaying the learning rate to 0')
    parser.add_argument('--size', type=int, default=256, help='size of the data crop (squared assumed)')
    parser.add_argument('--input_nc', type=int, default=3, help='number of channels of input data')
    parser.add_argument('--output_nc', type=int, default=3, help='number of channels of output data')
    parser.add_argument('--cuda', action='store_true', help='use GPU computation')
    parser.add_argument('--n_cpu', type=int, default=8, help='number of cpu threads to use during batch generation')
    opt = parser.parse_args()
    print(opt)

    if torch.cuda.is_available() and not opt.cuda:
        print("WARNING: You have a CUDA device, so you should probably run with --cuda")

    ###### Definition of variables ######
    # Networks
    # 生成器
    netG_A2B = Generator(opt.input_nc, opt.output_nc)
    netG_B2A = Generator(opt.output_nc, opt.input_nc)
    # 判别器
    netD_A = Discriminator(opt.input_nc)
    netD_B = Discriminator(opt.output_nc)

    if opt.cuda:
        netG_A2B.cuda()
        netG_B2A.cuda()
        netD_A.cuda()
        netD_B.cuda()

    # 用正态分布初始化模型权重
    netG_A2B.apply(weights_init_normal)
    netG_B2A.apply(weights_init_normal)
    netD_A.apply(weights_init_normal)
    netD_B.apply(weights_init_normal)

    # Lossess
    # 均方误差损失函数，用于衡量生成器生成的假样本与真实样本的差异。
    criterion_GAN = torch.nn.MSELoss()
    # 循环一致性损失函数（L1损失），用于确保转换后的图像可以被转换回原始图像。
    criterion_cycle = torch.nn.L1Loss()
    # 身份损失函数（L1损失），用于确保当真实图像输入到对应的生成器时，它应该与自身相近。
    criterion_identity = torch.nn.L1Loss()

    # Optimizers & LR schedulers
    optimizer_G = torch.optim.Adam(itertools.chain(netG_A2B.parameters(), netG_B2A.parameters()),
                                   lr=opt.lr, betas=(0.5, 0.999))
    optimizer_D_A = torch.optim.Adam(netD_A.parameters(), lr=opt.lr, betas=(0.5, 0.999))
    optimizer_D_B = torch.optim.Adam(netD_B.parameters(), lr=opt.lr, betas=(0.5, 0.999))

    # 学习率调度器。用于在训练过程中调整优化器的学习率。它们使用 LambdaLR 调度器，该调度器会根据提供的 lambda 函数来调整学习率
    lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=LambdaLR(opt.n_epochs, opt.epoch,
                                                                                       opt.decay_epoch).step)
    lr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(optimizer_D_A, lr_lambda=LambdaLR(opt.n_epochs, opt.epoch,
                                                                                           opt.decay_epoch).step)
    lr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(optimizer_D_B, lr_lambda=LambdaLR(opt.n_epochs, opt.epoch,
                                                                                           opt.decay_epoch).step)

    # Inputs & targets memory allocation
    Tensor = torch.cuda.FloatTensor if opt.cuda else torch.Tensor
    input_A = Tensor(opt.batchSize, opt.input_nc, opt.size, opt.size)
    input_B = Tensor(opt.batchSize, opt.output_nc, opt.size, opt.size)
    target_real = Variable(Tensor(opt.batchSize).fill_(1.0), requires_grad=False)
    target_fake = Variable(Tensor(opt.batchSize).fill_(0.0), requires_grad=False)

    # ReplayBuffer()  存储一定数量的先前生成的假样本。然后，在训练判别器时，它不仅会使用最新生成的假样本，还会从 ReplayBuffer 中随机抽取一些旧的假样本。
    # 这样可以防止判别器过于关注最新的假样本，从而忽视了其他可能的假样本
    fake_A_buffer = ReplayBuffer()
    fake_B_buffer = ReplayBuffer()

    # Dataset loader
    # 预处理图像
    transforms_ = [
        # 调整大小
        transforms.Resize(int(opt.size * 1.12), Image.BICUBIC),
        # 随即裁剪opt.size大小的区域
        transforms.RandomCrop(opt.size),
        # 以 50% 的概率对图像进行水平翻转
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        # 归一化
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ]
    dataloader = DataLoader(ImageDataset(opt.dataroot, transforms_=transforms_, unaligned=True),
                            batch_size=opt.batchSize,
                            # 在每个训练周期开始时，打乱数据集中的图像顺序
                            shuffle=True,
                            # 加载图像的线程数
                            num_workers=opt.n_cpu)

    # Loss plot
    # 训练过程中记录损失值并生成损失曲线
    logger = Logger(opt.n_epochs, len(dataloader))
    ###################################

    ###### Training ######
    for epoch in range(opt.epoch, opt.n_epochs):
        for i, batch in enumerate(dataloader):
            # Set model input
            # 从当前批次中获取真实的 A 类和 B 类图像，并将它们复制到 input_A 和 input_B 中
            real_A = Variable(input_A.copy_(batch['A']))
            real_B = Variable(input_B.copy_(batch['B']))

            ###### Generators A2B and B2A ######

            # 每次反向传播之前需要将梯度清零
            optimizer_G.zero_grad()

            # Identity loss
            # 在 CycleGAN 中，除了需要生成器 G_A2B 能将 A 类图像转换为看起来像 B 类的图像，我们还希望当输入就是 B 类图像时，G_A2B 能输出与输入相同的图像，即 G_A2B(B) ≈ B。
            # 同理，我们也希望 G_B2A(A) ≈ A。这就是所谓的身份损失。
            # G_A2B(B) should equal B if real B is fed
            # 输入真实图像real_B得到输出same_B
            same_B = netG_A2B(real_B)
            # 计算生成的same_B和真实的real_B之间的身份损失（L1损失），权重为5.0
            loss_identity_B = criterion_identity(same_B, real_B) * 5.0
            # G_B2A(A) should equal A if real A is fed
            # 同上
            same_A = netG_B2A(real_A)
            loss_identity_A = criterion_identity(same_A, real_A) * 5.0

            # 计算生成器 G_A2B 将 A 类图像转换为 B 类图像的能力，以及判别器 D_B 判断生成的假 B 类图像为真实图像的能力
            # GAN loss  GAN 损失衡量的是生成器生成的假图像能否被判别器判断为真实图像
            # 生成器根据输入的真实A类图像生成B类图像
            fake_B = netG_A2B(real_A)
            # 判别器对生成的B类图像进行判别
            pred_fake = netD_B(fake_B)
            # 计算判别器的判别结果和目标真实值之间的GAN损失（均方误差）
            loss_GAN_A2B = criterion_GAN(pred_fake, target_real)
            # 同上
            fake_A = netG_B2A(real_B)
            pred_fake = netD_A(fake_A)
            loss_GAN_B2A = criterion_GAN(pred_fake, target_real)

            # Cycle loss
            # 输入假的生成的B类图像，输出生成的A类图像。生成的A应该与真实的A相近
            recovered_A = netG_B2A(fake_B)
            # 计算生成的A与真实的A之间的损失（L1损失），权重为10.0
            loss_cycle_ABA = criterion_cycle(recovered_A, real_A) * 10.0

            recovered_B = netG_A2B(fake_A)
            loss_cycle_BAB = criterion_cycle(recovered_B, real_B) * 10.0

            # Total loss
            loss_G = loss_identity_A + loss_identity_B + loss_GAN_A2B + loss_GAN_B2A + loss_cycle_ABA + loss_cycle_BAB
            # 进行反向传播，计算梯度
            loss_G.backward()

            # 更新生成器权重
            optimizer_G.step()
            ###################################

            ###### Discriminator A ######
            # 判别器A的优化器梯度清零
            optimizer_D_A.zero_grad()

            ### 计算判别器A的损失并进行反向传播 ###
            # Real loss
            pred_real = netD_A(real_A)
            # 衡量的是判别器判断真实图像为真实的能力。
            loss_D_real = criterion_GAN(pred_real, target_real)

            # Fake loss
            fake_A = fake_A_buffer.push_and_pop(fake_A)
            pred_fake = netD_A(fake_A.detach())
            # 衡量的是判别器判断假图像为假的能力。
            loss_D_fake = criterion_GAN(pred_fake, target_fake)

            # Total loss
            loss_D_A = (loss_D_real + loss_D_fake) * 0.5
            loss_D_A.backward()

            optimizer_D_A.step()
            ###################################

            ###### Discriminator B ######
            optimizer_D_B.zero_grad()

            ### 计算判别器B的损失并进行反向传播 ###
            # Real loss
            pred_real = netD_B(real_B)
            loss_D_real = criterion_GAN(pred_real, target_real)

            # Fake loss
            fake_B = fake_B_buffer.push_and_pop(fake_B)
            pred_fake = netD_B(fake_B.detach())
            loss_D_fake = criterion_GAN(pred_fake, target_fake)

            # Total loss
            loss_D_B = (loss_D_real + loss_D_fake) * 0.5
            loss_D_B.backward()

            optimizer_D_B.step()
            ###################################

            # Progress report (http://localhost:8097)  在visdom上显示
            logger.log({'loss_G': loss_G, 'loss_G_identity': (loss_identity_A + loss_identity_B),
                        'loss_G_GAN': (loss_GAN_A2B + loss_GAN_B2A),
                        'loss_G_cycle': (loss_cycle_ABA + loss_cycle_BAB), 'loss_D': (loss_D_A + loss_D_B)},
                       images={'real_A': real_A, 'real_B': real_B, 'fake_A': fake_A, 'fake_B': fake_B})

        # Update learning rates
        lr_scheduler_G.step()
        lr_scheduler_D_A.step()
        lr_scheduler_D_B.step()

        # Save models checkpoints
        torch.save(netG_A2B.state_dict(), 'output/netG_A2B.pth')
        torch.save(netG_B2A.state_dict(), 'output/netG_B2A.pth')
        torch.save(netD_A.state_dict(), 'output/netD_A.pth')
        torch.save(netD_B.state_dict(), 'output/netD_B.pth')
    ###################################
